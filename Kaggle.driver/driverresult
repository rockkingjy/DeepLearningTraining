=========================driver04====================================================================================================================================================================
root@i3-8-1:/home/i3/Documents/Kaggle/driver/code# THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python driver04.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 Ti (CNMeM is disabled, cuDNN 4007)
Read drivers data
Read train images
Load folder c0
Load folder c1
Load folder c2
Load folder c3
Load folder c4
Load folder c5
Load folder c6
Load folder c7
Load folder c8
Load folder c9
Read train data time: 236.74 seconds
Unique drivers: 26
['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']
('Train shape:', (22424, 1, 64, 64))
(22424, 'train samples')
Read test images
Read 7972 images from 79726
Read 15944 images from 79726
Read 23916 images from 79726
Read 31888 images from 79726
Read 39860 images from 79726
Read 47832 images from 79726
Read 55804 images from 79726
Read 63776 images from 79726
Read 71748 images from 79726
Read 79720 images from 79726
Read test data time: 938.25 seconds
('Test shape:', (79726, 1, 64, 64))
(79726, 'test samples')
Start KFold number 1 from 13
('Split train: ', 20547, 20547)
('Split valid: ', 1877, 1877)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p026', 'p035', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p024', 'p039'])
Train on 20547 samples, validate on 1877 samples
Epoch 1/50
20547/20547 [==============================] - 18s - loss: 2.7953 - val_loss: 1.9603
Epoch 2/50
20547/20547 [==============================] - 17s - loss: 1.8547 - val_loss: 1.6217
Epoch 3/50
20547/20547 [==============================] - 17s - loss: 1.4886 - val_loss: 1.2576
Epoch 4/50
20547/20547 [==============================] - 17s - loss: 1.2510 - val_loss: 1.1350
Epoch 5/50
20547/20547 [==============================] - 18s - loss: 1.0957 - val_loss: 0.9472
Epoch 6/50
20547/20547 [==============================] - 17s - loss: 0.9652 - val_loss: 1.3066
Epoch 7/50
20547/20547 [==============================] - 17s - loss: 0.8835 - val_loss: 0.9868
1872/1877 [============================>.] - ETA: 0s('Score log_loss: ', 0.94723760605971685)
79726/79726 [==============================] - 26s     
Start KFold number 2 from 13
('Split train: ', 20882, 20882)
('Split valid: ', 1542, 1542)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p075', 'p081'])
('Test drivers: ', ['p026', 'p072'])
Train on 20882 samples, validate on 1542 samples
Epoch 1/50
20882/20882 [==============================] - 18s - loss: 0.9655 - val_loss: 0.8253
Epoch 2/50
20882/20882 [==============================] - 17s - loss: 0.8708 - val_loss: 0.8598
Epoch 3/50
20882/20882 [==============================] - 17s - loss: 0.8086 - val_loss: 1.1020
1520/1542 [============================>.] - ETA: 0s('Score log_loss: ', 0.82532424041659513)
79712/79726 [============================>.] - ETA: 0sStart KFold number 3 from 13
('Split train: ', 20792, 20792)
('Split valid: ', 1632, 1632)
('Train drivers: ', ['p002', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p012', 'p061'])
Train on 20792 samples, validate on 1632 samples
Epoch 1/50
20792/20792 [==============================] - 17s - loss: 0.8801 - val_loss: 0.8651
Epoch 2/50
20792/20792 [==============================] - 17s - loss: 0.8209 - val_loss: 0.7533
Epoch 3/50
20792/20792 [==============================] - 17s - loss: 0.7626 - val_loss: 0.9631
Epoch 4/50
20792/20792 [==============================] - 17s - loss: 0.7539 - val_loss: 0.8721
1632/1632 [==============================] - 0s     
('Score log_loss: ', 0.75331795182045025)
79726/79726 [==============================] - 25s     
Start KFold number 4 from 13
('Split train: ', 20754, 20754)
('Split valid: ', 1670, 1670)
('Train drivers: ', ['p002', 'p012', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p014', 'p056'])
Train on 20754 samples, validate on 1670 samples
Epoch 1/50
20754/20754 [==============================] - 17s - loss: 0.7864 - val_loss: 0.7558
Epoch 2/50
20754/20754 [==============================] - 19s - loss: 0.7480 - val_loss: 0.8193
Epoch 3/50
20754/20754 [==============================] - 17s - loss: 0.7144 - val_loss: 0.8347
1648/1670 [============================>.] - ETA: 0s('Score log_loss: ', 0.75577121663608215)
79726/79726 [==============================] - 25s     
Start KFold number 5 from 13
('Split train: ', 20586, 20586)
('Split valid: ', 1838, 1838)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p024', 'p026', 'p035', 'p039', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p022', 'p041'])
Train on 20586 samples, validate on 1838 samples
Epoch 1/50
20586/20586 [==============================] - 17s - loss: 0.7870 - val_loss: 0.5026
Epoch 2/50
20586/20586 [==============================] - 17s - loss: 0.7338 - val_loss: 0.4275
Epoch 3/50
20586/20586 [==============================] - 17s - loss: 0.7261 - val_loss: 0.4962
Epoch 4/50
20586/20586 [==============================] - 17s - loss: 0.6820 - val_loss: 0.6076
1824/1838 [============================>.] - ETA: 0s('Score log_loss: ', 0.42750582812861476)
79696/79726 [============================>.] - ETA: 0sStart KFold number 6 from 13
('Split train: ', 20825, 20825)
('Split valid: ', 1599, 1599)
('Train drivers: ', ['p002', 'p012', 'p014', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p015', 'p045'])
Train on 20825 samples, validate on 1599 samples
Epoch 1/50
20825/20825 [==============================] - 17s - loss: 0.6991 - val_loss: 0.4677
Epoch 2/50
20825/20825 [==============================] - 17s - loss: 0.6756 - val_loss: 0.6251
Epoch 3/50
20825/20825 [==============================] - 17s - loss: 0.6490 - val_loss: 0.5873
1584/1599 [============================>.] - ETA: 0s('Score log_loss: ', 0.46772451441927843)
79712/79726 [============================>.] - ETA: 0sStart KFold number 7 from 13
('Split train: ', 20335, 20335)
('Split valid: ', 2089, 2089)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p016', 'p049'])
Train on 20335 samples, validate on 2089 samples
Epoch 1/50
20335/20335 [==============================] - 17s - loss: 0.6979 - val_loss: 0.4565
Epoch 2/50
20335/20335 [==============================] - 17s - loss: 0.6648 - val_loss: 0.3388
Epoch 3/50
20335/20335 [==============================] - 17s - loss: 0.6561 - val_loss: 0.3563
Epoch 4/50
20335/20335 [==============================] - 17s - loss: 0.6376 - val_loss: 0.2998
Epoch 5/50
20335/20335 [==============================] - 17s - loss: 0.6202 - val_loss: 0.4054
Epoch 6/50
20335/20335 [==============================] - 17s - loss: 0.6077 - val_loss: 0.3822
2064/2089 [============================>.] - ETA: 0s('Score log_loss: ', 0.29984329498023388)
79712/79726 [============================>.] - ETA: 0sStart KFold number 8 from 13
('Split train: ', 20913, 20913)
('Split valid: ', 1511, 1511)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p045', 'p047', 'p049', 'p050', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p042', 'p051'])
Train on 20913 samples, validate on 1511 samples
Epoch 1/50
20913/20913 [==============================] - 18s - loss: 0.6544 - val_loss: 0.2543
Epoch 2/50
20913/20913 [==============================] - 17s - loss: 0.6299 - val_loss: 0.3469
Epoch 3/50
20913/20913 [==============================] - 18s - loss: 0.6207 - val_loss: 0.2999
1504/1511 [============================>.] - ETA: 0s('Score log_loss: ', 0.2542904914455173)
79696/79726 [============================>.] - ETA: 0sStart KFold number 9 from 13
('Split train: ', 20849, 20849)
('Split valid: ', 1575, 1575)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p049', 'p050', 'p051', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p047', 'p052'])
Train on 20849 samples, validate on 1575 samples
Epoch 1/50
20849/20849 [==============================] - 18s - loss: 0.6155 - val_loss: 0.2392
Epoch 2/50
20849/20849 [==============================] - 18s - loss: 0.6053 - val_loss: 0.3568
Epoch 3/50
20849/20849 [==============================] - 17s - loss: 0.5842 - val_loss: 0.3145
1568/1575 [============================>.] - ETA: 0s('Score log_loss: ', 0.23916142321336561)
79726/79726 [==============================] - 26s     
Start KFold number 10 from 13
('Split train: ', 20570, 20570)
('Split valid: ', 1854, 1854)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p064', 'p066'])
Train on 20570 samples, validate on 1854 samples
Epoch 1/50
20570/20570 [==============================] - 18s - loss: 0.5840 - val_loss: 0.5093
Epoch 2/50
20570/20570 [==============================] - 18s - loss: 0.5589 - val_loss: 0.8365
Epoch 3/50
20570/20570 [==============================] - 17s - loss: 0.5500 - val_loss: 0.7632
1840/1854 [============================>.] - ETA: 0s('Score log_loss: ', 0.5093354962987432)
79712/79726 [============================>.] - ETA: 0sStart KFold number 11 from 13
('Split train: ', 20820, 20820)
('Split valid: ', 1604, 1604)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p081'])
('Test drivers: ', ['p050', 'p075'])
Train on 20820 samples, validate on 1604 samples
Epoch 1/50
20820/20820 [==============================] - 18s - loss: 0.5735 - val_loss: 0.4735
Epoch 2/50
20820/20820 [==============================] - 17s - loss: 0.5613 - val_loss: 0.7528
Epoch 3/50
20820/20820 [==============================] - 18s - loss: 0.5412 - val_loss: 0.7305
1600/1604 [============================>.] - ETA: 0s('Score log_loss: ', 0.47348281231533296)
79712/79726 [============================>.] - ETA: 0sStart KFold number 12 from 13
('Split train: ', 20851, 20851)
('Split valid: ', 1573, 1573)
('Train drivers: ', ['p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])
('Test drivers: ', ['p002', 'p035'])
Train on 20851 samples, validate on 1573 samples
Epoch 1/50
20851/20851 [==============================] - 17s - loss: 0.6102 - val_loss: 0.3065
Epoch 2/50
20851/20851 [==============================] - 17s - loss: 0.5931 - val_loss: 0.2872
Epoch 3/50
20851/20851 [==============================] - 17s - loss: 0.5621 - val_loss: 0.3250
Epoch 4/50
20851/20851 [==============================] - 17s - loss: 0.5666 - val_loss: 0.3379
1552/1573 [============================>.] - ETA: 0s('Score log_loss: ', 0.28720030822047621)
79712/79726 [============================>.] - ETA: 0sStart KFold number 13 from 13
('Split train: ', 20364, 20364)
('Split valid: ', 2060, 2060)
('Train drivers: ', ['p002', 'p012', 'p014', 'p015', 'p016', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075'])
('Test drivers: ', ['p021', 'p081'])
Train on 20364 samples, validate on 2060 samples
Epoch 1/50
20364/20364 [==============================] - 17s - loss: 0.5696 - val_loss: 0.4569
Epoch 2/50
20364/20364 [==============================] - 17s - loss: 0.5593 - val_loss: 0.7355
Epoch 3/50
20364/20364 [==============================] - 17s - loss: 0.5363 - val_loss: 0.5177
2048/2060 [============================>.] - ETA: 0s('Score log_loss: ', 0.45691736800125271)
79696/79726 [============================>.] - ETA: 0s('Log_loss train independent avg: ', 0.51551418687390826)
Final log_loss: 0.515514186874, rows: 64 cols: 64 nfolds: 13 epoch: 50
=========================driver00====================================================================================================================================================================
root@i3-8-1:/home/i3/Documents/Kaggle# THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python script.py
Using gpu device 0: GeForce GTX 660 Ti (CNMeM is disabled, cuDNN 4007)
/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.
  "downsample module has been moved to the theano.tensor.signal.pool module.")
/usr/local/lib/python2.7/dist-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.
  border_mode=border_mode)
Read train images
Load folder c0
Load folder c1
Load folder c2
Load folder c3
Load folder c4
Load folder c5
Load folder c6
Load folder c7
Load folder c8
Load folder c9
('Train shape:', (20181, 1, 24, 24), 'Test shape:', (2243, 1, 24, 24))
Read test images
Read 7972 images from 79726
Read 15944 images from 79726
Read 23916 images from 79726
Read 31888 images from 79726
Read 39860 images from 79726
Read 47832 images from 79726
Read 55804 images from 79726
Read 63776 images from 79726
Read 71748 images from 79726
Read 79720 images from 79726
('iter:', 0, '| TL:', 0.97799999, '| VL:', 0.375, '| Vacc:', 0.89600003, '| Ratio:', 2.6099999, '| Time:', 3.2000000000000002)
('iter:', 1, '| TL:', 0.248, '| VL:', 0.192, '| Vacc:', 0.94400001, '| Ratio:', 1.29, '| Time:', 3.2000000000000002)
Making predictions
pred shape
(79726, 10)
Creating Submission
===================================================================================
root@i3-8-1:/home/i3/Documents/Kaggle/driver/code# THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python script.py
Using gpu device 0: GeForce GTX 660 Ti (CNMeM is disabled, cuDNN 4007)
/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.
  "downsample module has been moved to the theano.tensor.signal.pool module.")
/usr/local/lib/python2.7/dist-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.
  border_mode=border_mode)
Read train images
Load folder c0
Load folder c1
Load folder c2
Load folder c3
Load folder c4
Load folder c5
Load folder c6
Load folder c7
Load folder c8
Load folder c9
('Train shape:', (20181, 1, 24, 24), 'Test shape:', (2243, 1, 24, 24))
Read test images
Read 7972 images from 79726
Read 15944 images from 79726
Read 23916 images from 79726
Read 31888 images from 79726
Read 39860 images from 79726
Read 47832 images from 79726
Read 55804 images from 79726
Read 63776 images from 79726
Read 71748 images from 79726
Read 79720 images from 79726
('iter:', 0, '| TL:', 1.02, '| VL:', 0.44, '| Vacc:', 0.86199999, '| Ratio:', 2.3199999, '| Time:', 3.2999999999999998)
('iter:', 1, '| TL:', 0.29699999, '| VL:', 0.20200001, '| Vacc:', 0.94499999, '| Ratio:', 1.47, '| Time:', 3.2999999999999998)
('iter:', 2, '| TL:', 0.161, '| VL:', 0.185, '| Vacc:', 0.94300002, '| Ratio:', 0.87, '| Time:', 3.2999999999999998)
('iter:', 3, '| TL:', 0.097999997, '| VL:', 0.13600001, '| Vacc:', 0.95999998, '| Ratio:', 0.72000003, '| Time:', 3.2999999999999998)
('iter:', 4, '| TL:', 0.068999998, '| VL:', 0.134, '| Vacc:', 0.958, '| Ratio:', 0.50999999, '| Time:', 3.2999999999999998)
('iter:', 5, '| TL:', 0.052000001, '| VL:', 0.077, '| Vacc:', 0.97899997, '| Ratio:', 0.67000002, '| Time:', 3.2999999999999998)
('iter:', 6, '| TL:', 0.037, '| VL:', 0.079999998, '| Vacc:', 0.972, '| Ratio:', 0.47, '| Time:', 3.2999999999999998)
('iter:', 7, '| TL:', 0.035, '| VL:', 0.082000002, '| Vacc:', 0.97600001, '| Ratio:', 0.43000001, '| Time:', 3.2999999999999998)
('iter:', 8, '| TL:', 0.025, '| VL:', 0.061999999, '| Vacc:', 0.98400003, '| Ratio:', 0.40000001, '| Time:', 3.2999999999999998)
('iter:', 9, '| TL:', 0.022, '| VL:', 0.075000003, '| Vacc:', 0.97799999, '| Ratio:', 0.28999999, '| Time:', 3.2999999999999998)
('iter:', 10, '| TL:', 0.021, '| VL:', 0.108, '| Vacc:', 0.96899998, '| Ratio:', 0.2, '| Time:', 3.2999999999999998)
('iter:', 11, '| TL:', 0.015, '| VL:', 0.083999999, '| Vacc:', 0.97899997, '| Ratio:', 0.18000001, '| Time:', 3.2999999999999998)
('iter:', 12, '| TL:', 0.017000001, '| VL:', 0.071999997, '| Vacc:', 0.98000002, '| Ratio:', 0.23, '| Time:', 3.2999999999999998)
('iter:', 13, '| TL:', 0.012, '| VL:', 0.071999997, '| Vacc:', 0.98299998, '| Ratio:', 0.17, '| Time:', 3.2999999999999998)
('iter:', 14, '| TL:', 0.015, '| VL:', 0.063000001, '| Vacc:', 0.98400003, '| Ratio:', 0.23, '| Time:', 3.2999999999999998)
('iter:', 15, '| TL:', 0.015, '| VL:', 0.082000002, '| Vacc:', 0.98000002, '| Ratio:', 0.19, '| Time:', 3.2999999999999998)
('iter:', 16, '| TL:', 0.011, '| VL:', 0.106, '| Vacc:', 0.96799999, '| Ratio:', 0.11, '| Time:', 3.2999999999999998)
('iter:', 17, '| TL:', 0.011, '| VL:', 0.064999998, '| Vacc:', 0.98299998, '| Ratio:', 0.16, '| Time:', 3.2999999999999998)
('iter:', 18, '| TL:', 0.011, '| VL:', 0.068000004, '| Vacc:', 0.98299998, '| Ratio:', 0.16, '| Time:', 3.2999999999999998)
('iter:', 19, '| TL:', 0.011, '| VL:', 0.057, '| Vacc:', 0.98799998, '| Ratio:', 0.18000001, '| Time:', 3.2999999999999998)
('iter:', 20, '| TL:', 0.0, '| VL:', 0.039999999, '| Vacc:', 0.99199998, '| Ratio:', 0.0099999998, '| Time:', 3.2999999999999998)
('iter:', 21, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 22, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 23, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 24, '| TL:', 0.0, '| VL:', 0.046, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 25, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 26, '| TL:', 0.0, '| VL:', 0.046999998, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 27, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 28, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 29, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 30, '| TL:', 0.0, '| VL:', 0.050000001, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 31, '| TL:', 0.0, '| VL:', 0.052000001, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 32, '| TL:', 0.0, '| VL:', 0.052000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 33, '| TL:', 0.0, '| VL:', 0.054000001, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 34, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 35, '| TL:', 0.0, '| VL:', 0.056000002, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 36, '| TL:', 0.0, '| VL:', 0.052000001, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 37, '| TL:', 0.0, '| VL:', 0.055, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 38, '| TL:', 0.043000001, '| VL:', 0.061000001, '| Vacc:', 0.98400003, '| Ratio:', 0.69999999, '| Time:', 3.2999999999999998)
('iter:', 39, '| TL:', 0.003, '| VL:', 0.059999999, '| Vacc:', 0.98699999, '| Ratio:', 0.050000001, '| Time:', 3.2999999999999998)
('iter:', 40, '| TL:', 0.0, '| VL:', 0.057999998, '| Vacc:', 0.98799998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 41, '| TL:', 0.0, '| VL:', 0.057, '| Vacc:', 0.98900002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 42, '| TL:', 0.0, '| VL:', 0.057999998, '| Vacc:', 0.99000001, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 43, '| TL:', 0.0, '| VL:', 0.057999998, '| Vacc:', 0.99000001, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 44, '| TL:', 0.0, '| VL:', 0.057999998, '| Vacc:', 0.99000001, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 45, '| TL:', 0.0, '| VL:', 0.059, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 46, '| TL:', 0.0, '| VL:', 0.059999999, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 47, '| TL:', 0.0, '| VL:', 0.061000001, '| Vacc:', 0.99000001, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 48, '| TL:', 0.0, '| VL:', 0.063000001, '| Vacc:', 0.99000001, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 49, '| TL:', 0.0, '| VL:', 0.061999999, '| Vacc:', 0.99000001, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 50, '| TL:', 0.0, '| VL:', 0.064000003, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 51, '| TL:', 0.0, '| VL:', 0.064999998, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 52, '| TL:', 0.0, '| VL:', 0.066, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 53, '| TL:', 0.0, '| VL:', 0.067000002, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 54, '| TL:', 0.0, '| VL:', 0.067000002, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 55, '| TL:', 0.0, '| VL:', 0.068000004, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 56, '| TL:', 0.0, '| VL:', 0.068999998, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 57, '| TL:', 0.037999999, '| VL:', 0.139, '| Vacc:', 0.96200001, '| Ratio:', 0.27000001, '| Time:', 3.2999999999999998)
('iter:', 58, '| TL:', 0.0060000001, '| VL:', 0.048, '| Vacc:', 0.99000001, '| Ratio:', 0.12, '| Time:', 3.2999999999999998)
('iter:', 59, '| TL:', 0.001, '| VL:', 0.052000001, '| Vacc:', 0.98799998, '| Ratio:', 0.02, '| Time:', 3.2999999999999998)
('iter:', 60, '| TL:', 0.003, '| VL:', 0.075000003, '| Vacc:', 0.98500001, '| Ratio:', 0.039999999, '| Time:', 3.2999999999999998)
('iter:', 61, '| TL:', 0.017999999, '| VL:', 0.072999999, '| Vacc:', 0.98100001, '| Ratio:', 0.23999999, '| Time:', 3.2999999999999998)
('iter:', 62, '| TL:', 0.0070000002, '| VL:', 0.057999998, '| Vacc:', 0.98900002, '| Ratio:', 0.11, '| Time:', 3.2999999999999998)
('iter:', 63, '| TL:', 0.001, '| VL:', 0.061000001, '| Vacc:', 0.98900002, '| Ratio:', 0.02, '| Time:', 3.2999999999999998)
('iter:', 64, '| TL:', 0.0080000004, '| VL:', 0.071999997, '| Vacc:', 0.986, '| Ratio:', 0.11, '| Time:', 3.2999999999999998)
('iter:', 65, '| TL:', 0.0099999998, '| VL:', 0.044, '| Vacc:', 0.99000001, '| Ratio:', 0.22, '| Time:', 3.2999999999999998)
('iter:', 66, '| TL:', 0.0, '| VL:', 0.041999999, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 67, '| TL:', 0.0, '| VL:', 0.043000001, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 68, '| TL:', 0.0, '| VL:', 0.043000001, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 69, '| TL:', 0.0, '| VL:', 0.043000001, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 70, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 71, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 72, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 73, '| TL:', 0.0, '| VL:', 0.043000001, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 74, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 75, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 76, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 77, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 78, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 79, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 80, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 81, '| TL:', 0.0, '| VL:', 0.043000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 82, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 83, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 84, '| TL:', 0.0, '| VL:', 0.044, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 85, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 86, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 87, '| TL:', 0.0, '| VL:', 0.046999998, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 88, '| TL:', 0.0, '| VL:', 0.037999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 89, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 90, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 91, '| TL:', 0.0, '| VL:', 0.046, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 92, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 93, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 94, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 95, '| TL:', 0.0, '| VL:', 0.050000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 96, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 97, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 98, '| TL:', 0.0, '| VL:', 0.050999999, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 99, '| TL:', 0.0, '| VL:', 0.050000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 100, '| TL:', 0.035999998, '| VL:', 0.079999998, '| Vacc:', 0.98400003, '| Ratio:', 0.44999999, '| Time:', 3.2999999999999998)
('iter:', 101, '| TL:', 0.0040000002, '| VL:', 0.074000001, '| Vacc:', 0.98799998, '| Ratio:', 0.050000001, '| Time:', 3.2999999999999998)
('iter:', 102, '| TL:', 0.0020000001, '| VL:', 0.12899999, '| Vacc:', 0.97899997, '| Ratio:', 0.0099999998, '| Time:', 3.2999999999999998)
('iter:', 103, '| TL:', 0.0070000002, '| VL:', 0.063000001, '| Vacc:', 0.991, '| Ratio:', 0.11, '| Time:', 3.2999999999999998)
('iter:', 104, '| TL:', 0.001, '| VL:', 0.072999999, '| Vacc:', 0.98799998, '| Ratio:', 0.0099999998, '| Time:', 3.2999999999999998)
('iter:', 105, '| TL:', 0.0099999998, '| VL:', 0.071000002, '| Vacc:', 0.98199999, '| Ratio:', 0.14, '| Time:', 3.2999999999999998)
('iter:', 106, '| TL:', 0.0060000001, '| VL:', 0.050999999, '| Vacc:', 0.98799998, '| Ratio:', 0.12, '| Time:', 3.2999999999999998)
('iter:', 107, '| TL:', 0.0, '| VL:', 0.046, '| Vacc:', 0.99000001, '| Ratio:', 0.0099999998, '| Time:', 3.2999999999999998)
('iter:', 108, '| TL:', 0.0, '| VL:', 0.046, '| Vacc:', 0.99000001, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 109, '| TL:', 0.013, '| VL:', 0.064999998, '| Vacc:', 0.98699999, '| Ratio:', 0.19, '| Time:', 3.2999999999999998)
('iter:', 110, '| TL:', 0.011, '| VL:', 0.07, '| Vacc:', 0.98299998, '| Ratio:', 0.16, '| Time:', 3.2999999999999998)
('iter:', 111, '| TL:', 0.0020000001, '| VL:', 0.046, '| Vacc:', 0.99199998, '| Ratio:', 0.050000001, '| Time:', 3.2999999999999998)
('iter:', 112, '| TL:', 0.0, '| VL:', 0.041999999, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 113, '| TL:', 0.0, '| VL:', 0.041000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 114, '| TL:', 0.0, '| VL:', 0.041000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 115, '| TL:', 0.0, '| VL:', 0.041000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 116, '| TL:', 0.0, '| VL:', 0.039999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 117, '| TL:', 0.0, '| VL:', 0.041000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 118, '| TL:', 0.0, '| VL:', 0.041000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 119, '| TL:', 0.0, '| VL:', 0.041000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 120, '| TL:', 0.0, '| VL:', 0.041000001, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 121, '| TL:', 0.0, '| VL:', 0.041999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 122, '| TL:', 0.0, '| VL:', 0.041000001, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 123, '| TL:', 0.0, '| VL:', 0.041999999, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 124, '| TL:', 0.0, '| VL:', 0.043000001, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 125, '| TL:', 0.0, '| VL:', 0.043000001, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 126, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 127, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 128, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 129, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 130, '| TL:', 0.0, '| VL:', 0.045000002, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 131, '| TL:', 0.0, '| VL:', 0.046999998, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 132, '| TL:', 0.0, '| VL:', 0.046999998, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 133, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 134, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 135, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 136, '| TL:', 0.0, '| VL:', 0.050999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 137, '| TL:', 0.0, '| VL:', 0.050000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 138, '| TL:', 0.0, '| VL:', 0.052000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 139, '| TL:', 0.0, '| VL:', 0.052999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 140, '| TL:', 0.0, '| VL:', 0.052999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 141, '| TL:', 0.0, '| VL:', 0.052999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 142, '| TL:', 0.0, '| VL:', 0.054000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 143, '| TL:', 0.0, '| VL:', 0.054000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 144, '| TL:', 0.0, '| VL:', 0.056000002, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 145, '| TL:', 0.0, '| VL:', 0.056000002, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 146, '| TL:', 0.0, '| VL:', 0.056000002, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 147, '| TL:', 0.0, '| VL:', 0.057999998, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 148, '| TL:', 0.0, '| VL:', 0.057, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 149, '| TL:', 0.0, '| VL:', 0.059999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 150, '| TL:', 0.0, '| VL:', 0.059, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 151, '| TL:', 0.0, '| VL:', 0.061999999, '| Vacc:', 0.995, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 152, '| TL:', 0.0, '| VL:', 0.061999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 153, '| TL:', 0.0, '| VL:', 0.075999998, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 154, '| TL:', 0.035999998, '| VL:', 0.085000001, '| Vacc:', 0.98400003, '| Ratio:', 0.41999999, '| Time:', 3.2999999999999998)
('iter:', 155, '| TL:', 0.0020000001, '| VL:', 0.061000001, '| Vacc:', 0.99000001, '| Ratio:', 0.029999999, '| Time:', 3.2999999999999998)
('iter:', 156, '| TL:', 0.0020000001, '| VL:', 0.086000003, '| Vacc:', 0.98500001, '| Ratio:', 0.02, '| Time:', 3.2999999999999998)
('iter:', 157, '| TL:', 0.0070000002, '| VL:', 0.048, '| Vacc:', 0.99199998, '| Ratio:', 0.14, '| Time:', 3.2999999999999998)
('iter:', 158, '| TL:', 0.0, '| VL:', 0.046999998, '| Vacc:', 0.991, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 159, '| TL:', 0.0, '| VL:', 0.046999998, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 160, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 161, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 162, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 163, '| TL:', 0.0, '| VL:', 0.048, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 164, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 165, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 166, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 167, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99199998, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 168, '| TL:', 0.0, '| VL:', 0.048999999, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 169, '| TL:', 0.0, '| VL:', 0.050000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 170, '| TL:', 0.0, '| VL:', 0.050000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 171, '| TL:', 0.0, '| VL:', 0.050000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 172, '| TL:', 0.0, '| VL:', 0.050999999, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 173, '| TL:', 0.0, '| VL:', 0.050999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 174, '| TL:', 0.0, '| VL:', 0.052000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 175, '| TL:', 0.0, '| VL:', 0.052000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 176, '| TL:', 0.0, '| VL:', 0.052000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 177, '| TL:', 0.0, '| VL:', 0.052000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 178, '| TL:', 0.0, '| VL:', 0.052999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 179, '| TL:', 0.0, '| VL:', 0.052999999, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 180, '| TL:', 0.0, '| VL:', 0.054000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 181, '| TL:', 0.0, '| VL:', 0.054000001, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 182, '| TL:', 0.0, '| VL:', 0.055, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 183, '| TL:', 0.0, '| VL:', 0.055, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 184, '| TL:', 0.0, '| VL:', 0.055, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 185, '| TL:', 0.0, '| VL:', 0.046999998, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 186, '| TL:', 0.0, '| VL:', 0.057, '| Vacc:', 0.99400002, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 187, '| TL:', 0.0, '| VL:', 0.057999998, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 188, '| TL:', 0.0, '| VL:', 0.057999998, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 189, '| TL:', 0.0, '| VL:', 0.059, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 190, '| TL:', 0.0, '| VL:', 0.061000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 191, '| TL:', 0.0, '| VL:', 0.061000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 192, '| TL:', 0.0, '| VL:', 0.063000001, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 193, '| TL:', 0.0, '| VL:', 0.064999998, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 194, '| TL:', 0.0, '| VL:', 0.064999998, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 195, '| TL:', 0.0, '| VL:', 0.067000002, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 196, '| TL:', 0.0, '| VL:', 0.07, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 197, '| TL:', 0.0, '| VL:', 0.072999999, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 198, '| TL:', 0.0, '| VL:', 0.075999998, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
('iter:', 199, '| TL:', 0.0, '| VL:', 0.079999998, '| Vacc:', 0.99299997, '| Ratio:', 0.0, '| Time:', 3.2999999999999998)
Making predictions
pred shape
(79726, 10)
Creating Submission

